---
title: "UFront: Toward A Unified MLIR Frontend for Deep Learning."
collection: publications
permalink: /publication/2024-09-30-UFront
excerpt: 'A unified frontend for the MLIR ecosystem which is able to transform popular models written in different frameworks to standard MLIR dialect.'
date: 2024-09-30
venue: 'IEEE/ACM ASE 2024'
paperurl: 'https://doi.org/10.1145/3691620.3695002'
citation: '<b>Guoqing Bao</b>, Heng Shi, Chengyi Cui, Yalin Zhang, and Jianguo Yao, "UFront: Toward A Unified MLIR Frontend for Deep Learning.", In 39th IEEE/ACM International Conference on Automated Software Engineering (ASEâ€™24), October 27-November 1, 2024, Sacramento, CA, USA. https://doi.org/10.1145/3691620.3695002'


---
We proposed a unified frontend for the MLIR ecosystem which is able to transform popular models written in different frameworks to standard MLIR dialect making end-to-end code generation and optimization of popular DNN models expressed with various formats in one workflow for the first time. Unlike existing MLIR frontend compilers tailored for specific model formats (DSL inputs), UFront decouples highand lower-level IR transformations into two distinct stages. First, it traces, fuses, and maps computational nodes from various ML frameworks into standard DNN operators under a common interface without relying on MLIR passes. This produces unified high-level model representations and allows for flexible graph-level optimizations. Next, it converts the high-level IR into the standard MLIR dialect using proposed lowering patterns. This approach not only makes UFront compile faster but also generates more efficient code. Furthermore, the two-stage approach ensures compatibility with existing MLIR compiler backends like IREE, reducing software fragmentation in MLIR frontends.
